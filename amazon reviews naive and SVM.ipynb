{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "967551a8",
   "metadata": {},
   "source": [
    "# Classifying Texts with a Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd72275b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>watch for the song no me queda mas by far the ...</td>\n",
       "      <td>Acompanhado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a final  precious gift from roy to his fans i ...</td>\n",
       "      <td>Acompanhado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>like a cat dragged in from the rain depeche mo...</td>\n",
       "      <td>Acompanhado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>folk/rock  country/rock what a great artist. d...</td>\n",
       "      <td>Acompanhado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>one of my very favorite \"sing along\" albums if...</td>\n",
       "      <td>Acompanhado</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review        class\n",
       "0  watch for the song no me queda mas by far the ...  Acompanhado\n",
       "1  a final  precious gift from roy to his fans i ...  Acompanhado\n",
       "2  like a cat dragged in from the rain depeche mo...  Acompanhado\n",
       "3  folk/rock  country/rock what a great artist. d...  Acompanhado\n",
       "4  one of my very favorite \"sing along\" albums if...  Acompanhado"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data_set_amazon.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c153195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'watch for the song no me queda mas by far the highlight of the album is the song  no me queda mas. i used to play it for my students while teaching in albania. we had a lesson where each student had to bring a song  we would listen to it  and we would explain the personal significance it had for us. the song brings gentleness to my heart  the sweetness that was selena  the simple and adorned style she sometimes could do so well. perhaps what impresses me the most about selena is the amazing variety of styles she could sing in. my only wish she could have sung more songs like the beautiful lo me queda mas.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0, 'review']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a2c02f",
   "metadata": {},
   "source": [
    "# Vector representation of text\n",
    "Let's represent the text as a vector of indicators of occurrences of words from some dictionary in the text. This is the simplest BOF model.\n",
    "\n",
    "Let's form a dictionary based on the training dataset. To do this, we use the CountVectorizer module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13f7e7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(binary=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(binary=True)\n",
    "vectorizer.fit(df.review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7836292f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11164"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f654d09",
   "metadata": {},
   "source": [
    "# Splitting a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a15e11be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c66059c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Let's translate the entire set of texts of the training and test dataset into sets of vectors:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d3beb85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((410, 11164), (103, 11164))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = vectorizer.transform(df_train.review)\n",
    "X_test = vectorizer.transform(df_test.review)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3545e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>This book is the last word on the F-14. I want...</td>\n",
       "      <td>Sozinho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>one of the few hip-hop cd's i can love i first...</td>\n",
       "      <td>Família</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>top 10 movie of all time... i've shown this mo...</td>\n",
       "      <td>Amigos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>I shall just get right to the point: if you ar...</td>\n",
       "      <td>Sozinho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>This book seems to be missing a lot of words. ...</td>\n",
       "      <td>Sozinho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>closely patterned after the book most of the f...</td>\n",
       "      <td>Casal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>the best cd in the universe not many people ha...</td>\n",
       "      <td>Amigos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>beautiful portrayal of washington my girlfrien...</td>\n",
       "      <td>Amigos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>indescribable my friend is a cheap-70's-horror...</td>\n",
       "      <td>Sozinho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>who'd break into a box car full of sugar?! thi...</td>\n",
       "      <td>Casal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>410 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review    class\n",
       "95   This book is the last word on the F-14. I want...  Sozinho\n",
       "279  one of the few hip-hop cd's i can love i first...  Família\n",
       "425  top 10 movie of all time... i've shown this mo...   Amigos\n",
       "109  I shall just get right to the point: if you ar...  Sozinho\n",
       "91   This book seems to be missing a lot of words. ...  Sozinho\n",
       "..                                                 ...      ...\n",
       "474  closely patterned after the book most of the f...    Casal\n",
       "397  the best cd in the universe not many people ha...   Amigos\n",
       "443  beautiful portrayal of washington my girlfrien...   Amigos\n",
       "35   indescribable my friend is a cheap-70's-horror...  Sozinho\n",
       "500  who'd break into a box car full of sugar?! thi...    Casal\n",
       "\n",
       "[410 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edeef74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5cdb75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c6f095c",
   "metadata": {},
   "source": [
    "# BernoulliNB\n",
    "BernoulliNB - Bayesian classifier for binarized features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f48604c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "clf = BernoulliNB().fit(X_train, df_train['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2de5ef",
   "metadata": {},
   "source": [
    "Prior probabilities for categories (how did these numbers come about?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0364cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04390244, 0.13170732, 0.14146341, 0.22195122, 0.46097561])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(clf.class_log_prior_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11955013",
   "metadata": {},
   "source": [
    "Let's display the 10 most significant words in each category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a01a2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg: to was for of is this in and it the\n",
      "pos: was in is of to it my the this and\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "def show_top10(classifier, vectorizer, categories=('neg', 'pos')):\n",
    "    feature_names = np.asarray(vectorizer.get_feature_names())\n",
    "    for i, category in enumerate(categories):\n",
    "        top10 = np.argsort(classifier.feature_log_prob_[i])[-10:]\n",
    "        print(\"%s: %s\" % (category, \" \".join(feature_names[top10])))\n",
    "\n",
    "show_top10(clf, vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4906d1",
   "metadata": {},
   "source": [
    "We see that the top includes commonly used words that are not specific to any category. This remains to be dealt with, for now, let's run the predict method on the training part of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dfdb7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " Acompanhado       0.00      0.00      0.00        18\n",
      "      Amigos       1.00      0.07      0.14        54\n",
      "       Casal       1.00      0.03      0.07        58\n",
      "     Família       0.46      1.00      0.63        91\n",
      "     Sozinho       0.86      0.95      0.90       189\n",
      "\n",
      "    accuracy                           0.67       410\n",
      "   macro avg       0.67      0.41      0.35       410\n",
      "weighted avg       0.77      0.67      0.59       410\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predicts = clf.predict(X_train)\n",
    "print(classification_report(df_train['class'], predicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951ad151",
   "metadata": {},
   "source": [
    "Compare with the metrics on the test part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97b7bc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " Acompanhado       0.00      0.00      0.00         3\n",
      "      Amigos       0.00      0.00      0.00        15\n",
      "       Casal       0.00      0.00      0.00        10\n",
      "     Família       0.32      0.94      0.48        17\n",
      "     Sozinho       0.94      0.86      0.90        58\n",
      "\n",
      "    accuracy                           0.64       103\n",
      "   macro avg       0.25      0.36      0.28       103\n",
      "weighted avg       0.58      0.64      0.59       103\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hp\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hp\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predicts = clf.predict(X_test)\n",
    "print(classification_report(df_test['class'], predicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f19e1f1",
   "metadata": {},
   "source": [
    "The model clearly needs to be improved. First of all, it makes sense to pay attention to the feature vector.\n",
    "\n",
    "# The Bag-of-Words Model\n",
    "\n",
    "When constructing a feature vector, we will take into account not just the fact that a word occurs in the text, but also count the number of occurrences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5510f530",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(binary=False).fit(df.review)\n",
    "\n",
    "X_train_counts = count_vect.transform(df_train.review)\n",
    "X_test_counts = count_vect.transform(df_test.review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e535acf",
   "metadata": {},
   "source": [
    "For example, let's display the words together and the number of occurrences for the first text from the training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96626c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'14': 2,\n",
       " '1980': 1,\n",
       " '1988': 1,\n",
       " '79': 1,\n",
       " 'about': 1,\n",
       " 'against': 1,\n",
       " 'aircraft': 1,\n",
       " 'and': 1,\n",
       " 'before': 1,\n",
       " 'book': 1,\n",
       " 'but': 1,\n",
       " 'during': 1,\n",
       " 'fall': 1,\n",
       " 'how': 1,\n",
       " 'iran': 2,\n",
       " 'iraq': 1,\n",
       " 'iraqi': 1,\n",
       " 'is': 1,\n",
       " 'last': 1,\n",
       " 'mentioned': 1,\n",
       " 'more': 1,\n",
       " 'nothing': 1,\n",
       " 'of': 1,\n",
       " 'on': 1,\n",
       " 'performed': 1,\n",
       " 'read': 1,\n",
       " 'shah': 1,\n",
       " 'sold': 1,\n",
       " 'soviet': 1,\n",
       " 'supplied': 1,\n",
       " 'that': 1,\n",
       " 'the': 6,\n",
       " 'they': 1,\n",
       " 'this': 1,\n",
       " 'to': 2,\n",
       " 'wanted': 1,\n",
       " 'war': 1,\n",
       " 'was': 1,\n",
       " 'were': 1,\n",
       " 'word': 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(count_vect.inverse_transform(X_train_counts[0])[0], X_train_counts[0].data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699ced72",
   "metadata": {},
   "source": [
    "This text representation is called Bag-of-Words (BOF).\n",
    "\n",
    "# MultinomialNB\n",
    "\n",
    "MultinomialNB is a Bayesian classifier for features expressing the number of events that have occurred:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d15ea704",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB().fit(X_train_counts, df_train['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "288da3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " Acompanhado       1.00      0.17      0.29        18\n",
      "      Amigos       0.98      0.85      0.91        54\n",
      "       Casal       1.00      0.55      0.71        58\n",
      "     Família       0.78      0.95      0.86        91\n",
      "     Sozinho       0.86      0.99      0.92       189\n",
      "\n",
      "    accuracy                           0.86       410\n",
      "   macro avg       0.92      0.70      0.74       410\n",
      "weighted avg       0.88      0.86      0.85       410\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Metrics on learning:\n",
    "predicts = clf.predict(X_train_counts)\n",
    "print(classification_report(df_train['class'], predicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90fc100",
   "metadata": {},
   "source": [
    "Let's evaluate the new model on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a41b08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " Acompanhado       0.00      0.00      0.00         3\n",
      "      Amigos       0.00      0.00      0.00        15\n",
      "       Casal       0.00      0.00      0.00        10\n",
      "     Família       0.25      0.41      0.31        17\n",
      "     Sozinho       0.73      0.93      0.82        58\n",
      "\n",
      "    accuracy                           0.59       103\n",
      "   macro avg       0.20      0.27      0.23       103\n",
      "weighted avg       0.45      0.59      0.51       103\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hp\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hp\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X_test_counts = count_vect.transform(df_test.review)\n",
    "predicts = clf.predict(X_test_counts)\n",
    "print(classification_report(df_test['class'], predicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ea53cb",
   "metadata": {},
   "source": [
    "Non-specific words are still leading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85e5b106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg: that was this is in it to of and the\n",
      "pos: in was my is of to this and it the\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "show_top10(clf, count_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f503dc84",
   "metadata": {},
   "source": [
    "It's time to get rid of them by removing the stop words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27af48e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "count_vect = CountVectorizer(stop_words=ENGLISH_STOP_WORDS, binary=False).fit(df.review)\n",
    "\n",
    "X_train_counts = count_vect.transform(df_train.review)\n",
    "X_test_counts = count_vect.transform(df_test.review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5279e34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB().fit(X_train_counts, df_train['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd19ea5",
   "metadata": {},
   "source": [
    "Now let see if we improved the model after removing the stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3ae846b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " Acompanhado       0.00      0.00      0.00         3\n",
      "      Amigos       0.64      0.47      0.54        15\n",
      "       Casal       0.50      0.10      0.17        10\n",
      "     Família       0.39      0.76      0.52        17\n",
      "     Sozinho       0.89      0.88      0.89        58\n",
      "\n",
      "    accuracy                           0.70       103\n",
      "   macro avg       0.49      0.44      0.42       103\n",
      "weighted avg       0.71      0.70      0.68       103\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hp\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hp\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predicts = clf.predict(X_test_counts)\n",
    "print(classification_report(df_test['class'], predicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2332e81a",
   "metadata": {},
   "source": [
    "The model added a few more percent of accuracy! Now in the top more meaningful words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "066f4363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg: best orbison roy good time just great song movie album\n",
      "pos: songs don friends just like album cd song great movie\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "show_top10(clf, count_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18827783",
   "metadata": {},
   "source": [
    "Let's go further along the path of improving the indicative description.\n",
    "\n",
    "# TF-IDF\n",
    "\n",
    "TF-IDF - a measure of the significance of a word for a document, calculated as the product of the Term Frequency value (the frequency of occurrence of the word in the document) by the Inverse Document Frequency value (the reciprocal of the proportion of documents in the dataset in which the given word occurs). You can often find logarithms in the TF-IDF calculation formula.\n",
    "\n",
    "Let's make a dictionary and calculate the IDF measures for the words of the training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8db7094e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=ENGLISH_STOP_WORDS)\n",
    "vectorizer = vectorizer.fit(df.review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06008c1a",
   "metadata": {},
   "source": [
    "Let's convert the texts of the training and test dataset into vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15ffd85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectors = vectorizer.transform(df_train.review)\n",
    "X_test_vectors = vectorizer.transform(df_test.review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda1f463",
   "metadata": {},
   "source": [
    "The non-zero elements of the vectors contain the values ​​of the TF-IDF measure for words from the document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "531213b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13814654, 0.14942613, 0.13814654, 0.22487051, 0.22487051,\n",
       "       0.18185537, 0.22487051, 0.07973702, 0.21094837, 0.16633591,\n",
       "       0.22487051, 0.22487051, 0.44974102, 0.17322618, 0.06410383,\n",
       "       0.21094837, 0.22487051, 0.19340855, 0.21094837, 0.40214091])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectors[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56bf835c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['book', 'read', 'word', 'wanted', 'war', 'mentioned', 'fall',\n",
       "       'sold', '1988', 'performed', '1980', 'aircraft', 'shah', 'soviet',\n",
       "       'iraqi', 'iraq', 'supplied', '79', '14', 'iran'], dtype='<U22')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's derive the words from the first document in ascending order from the TF-IDF measure:\n",
    "vectorizer.inverse_transform(X_train_vectors[0])[0][np.argsort(X_train_vectors[0].data)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e82308",
   "metadata": {},
   "source": [
    "As it was planned, at the beginning of the list were commonly used words, and towards the end of the list - words that are specific to this particular document.\n",
    "\n",
    "Let's apply the MultinomialNB model (how to adapt the MultinomialNB model for non-integer features?):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d2c545f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB().fit(X_train_vectors, df_train['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f8362992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg: just orbison songs music best latin song album great movie\n",
      "pos: don friend watch songs album great film friends cd movie\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Top list of words by category:\n",
    "show_top10(clf, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8e45ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " Acompanhado       0.00      0.00      0.00        18\n",
      "      Amigos       1.00      0.02      0.04        54\n",
      "       Casal       1.00      0.03      0.07        58\n",
      "     Família       0.84      0.81      0.83        91\n",
      "     Sozinho       0.59      1.00      0.74       189\n",
      "\n",
      "    accuracy                           0.65       410\n",
      "   macro avg       0.69      0.37      0.33       410\n",
      "weighted avg       0.73      0.65      0.54       410\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hp\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hp\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Metrics on learning:\n",
    "predicts = clf.predict(X_train_vectors)\n",
    "print(classification_report(df_train['class'], predicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95f68c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " Acompanhado       0.00      0.00      0.00         3\n",
      "      Amigos       0.00      0.00      0.00        15\n",
      "       Casal       0.00      0.00      0.00        10\n",
      "     Família       0.33      0.06      0.10        17\n",
      "     Sozinho       0.58      1.00      0.73        58\n",
      "\n",
      "    accuracy                           0.57       103\n",
      "   macro avg       0.18      0.21      0.17       103\n",
      "weighted avg       0.38      0.57      0.43       103\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hp\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hp\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Model metrics on the test dataset:\n",
    "X_test_vectors = vectorizer.transform(df_test.review)\n",
    "predicts = clf.predict(X_test_vectors)\n",
    "print(classification_report(df_test['class'], predicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93cadfd",
   "metadata": {},
   "source": [
    "we got the accuracy even more less than the previous one which was 59. Can be better!\n",
    "\n",
    "Let's try to count not only single words, but also pairs of words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "64ff3f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=ENGLISH_STOP_WORDS, ngram_range=(1, 2)).fit(df.review)\n",
    "\n",
    "X_train_vectors = vectorizer.transform(df_train.review)\n",
    "X_test_vectors = vectorizer.transform(df_test.review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618a123c",
   "metadata": {},
   "source": [
    "\n",
    "Let's derive the words from the first document in ascending order from the TF-IDF measure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7131c4dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['book', 'read', 'word', 'wanted', 'war', 'mentioned', 'fall',\n",
       "       'sold', '1988', '1980', 'performed', 'aircraft', 'fall shah',\n",
       "       'book word', 'word 14', 'iran fall', '79 14', '79', '1988 iran',\n",
       "       '1980 1988', '14 wanted', 'aircraft 1980', 'iran iraq', 'iraqi',\n",
       "       'iraq war', 'war mentioned', 'wanted read', 'supplied iraqi',\n",
       "       'supplied', 'soviet supplied', 'soviet', 'iraq', 'sold iran',\n",
       "       'shah', 'read 79', 'performed soviet', 'iraqi aircraft', '14 sold',\n",
       "       'shah performed', '14', 'iran'], dtype='<U34')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.inverse_transform(X_train_vectors[0])[0][np.argsort(X_train_vectors[0].data)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b252425b",
   "metadata": {},
   "source": [
    "Apply the MultinomialNB model again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b3a7e8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB().fit(X_train_vectors, df_train['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "04aeb5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " Acompanhado       0.00      0.00      0.00        18\n",
      "      Amigos       1.00      0.02      0.04        54\n",
      "       Casal       0.00      0.00      0.00        58\n",
      "     Família       0.99      0.92      0.95        91\n",
      "     Sozinho       0.58      1.00      0.74       189\n",
      "\n",
      "    accuracy                           0.67       410\n",
      "   macro avg       0.51      0.39      0.35       410\n",
      "weighted avg       0.62      0.67      0.56       410\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hp\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hp\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# lets go again\n",
    "predicts = clf.predict(X_train_vectors)\n",
    "print(classification_report(df_train['class'], predicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0181bb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " Acompanhado       0.00      0.00      0.00         3\n",
      "      Amigos       0.00      0.00      0.00        15\n",
      "       Casal       0.00      0.00      0.00        10\n",
      "     Família       0.00      0.00      0.00        17\n",
      "     Sozinho       0.56      1.00      0.72        58\n",
      "\n",
      "    accuracy                           0.56       103\n",
      "   macro avg       0.11      0.20      0.14       103\n",
      "weighted avg       0.32      0.56      0.41       103\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hp\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hp\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# on test data\n",
    "X_test_vectors = vectorizer.transform(df_test.review)\n",
    "predicts = clf.predict(X_test_vectors)\n",
    "print(classification_report(df_test['class'], predicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a617c63d",
   "metadata": {},
   "source": [
    "# SVM\n",
    "As we have done with the Naive Bayes, now we will try SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc707e08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d204b3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "param_grid = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "68ff7fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.5s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.3s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.3s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.3s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.3s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.4s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.3s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.5s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.5s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.4s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.3s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.4s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.4s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.4s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.4s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.4s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.4s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.4s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.4s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.4s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.3s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.3s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.3s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.3s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.2s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.3s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.3s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.3s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.3s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.3s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.2s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.2s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.2s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.2s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.2s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.1s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.1s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.1s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.1s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.1s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.3s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.3s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.3s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.3s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.3s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.3s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.3s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.3s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.3s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.3s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.3s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.3s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.3s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.3s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.3s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.3s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.3s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.3s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.3s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.3s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.3s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.3s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.3s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.3s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.3s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.3s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.3s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.3s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.3s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.3s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.2s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.2s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.2s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.2s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.2s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.2s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.2s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.2s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.2s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.2s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.3s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.3s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.3s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.3s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.3s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.3s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.3s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.3s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.4s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.3s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.3s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.3s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.3s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.3s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.3s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.3s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.3s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.3s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.3s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.3s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.3s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.4s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.4s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.3s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.3s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.3s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.3s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.3s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.3s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.4s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.3s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.4s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.3s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.3s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.3s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.3s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.3s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.3s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.3s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.4s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.3s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.4s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.3s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.3s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.3s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.3s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.3s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.3s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.3s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.3s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.3s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.3s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.3s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.3s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.3s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.3s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.3s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.3s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.3s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.3s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.3s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.3s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.3s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.3s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.3s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.3s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.3s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.2s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.3s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.3s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.3s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.3s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.3s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.3s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.4s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.3s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.2s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.2s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.3s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.2s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.3s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.3s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.3s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.3s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.3s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.3s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.3s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.3s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.3s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.3s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001],\n",
       "                         'kernel': ['rbf', 'poly', 'sigmoid']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=2)\n",
    "grid.fit(X_train,df_train['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc6c9db",
   "metadata": {},
   "source": [
    "so we got the following accuracy with SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "53dc0bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  1  1  1]\n",
      " [ 0 10  0  4  1]\n",
      " [ 0  0  5  4  1]\n",
      " [ 0  5  4  6  2]\n",
      " [ 0  1  2  5 50]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Acompanhado       0.00      0.00      0.00         3\n",
      "      Amigos       0.62      0.67      0.65        15\n",
      "       Casal       0.42      0.50      0.45        10\n",
      "     Família       0.30      0.35      0.32        17\n",
      "     Sozinho       0.91      0.86      0.88        58\n",
      "\n",
      "    accuracy                           0.69       103\n",
      "   macro avg       0.45      0.48      0.46       103\n",
      "weighted avg       0.69      0.69      0.69       103\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hp\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hp\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "grid_predictions = grid.predict(X_test)\n",
    "print(confusion_matrix(df_test['class'],grid_predictions))\n",
    "print(classification_report(df_test['class'],grid_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd891738",
   "metadata": {},
   "source": [
    "# KFold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "383fa6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train['review']\n",
    "Y = df_train['class']\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000,ngram_range=(2,2))\n",
    "# TF-IDF feature matrix\n",
    "X= tfidf_vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "967cf5a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3, 1, 4, 4, 0, 0, 4, 4, 3, 3, 2, 3, 4, 2, 3, 4, 2, 3, 4, 0, 3,\n",
       "       3, 2, 3, 3, 4, 1, 4, 4, 2, 1, 4, 3, 4, 3, 4, 4, 3, 2, 1, 4, 4, 2,\n",
       "       1, 0, 4, 4, 0, 4, 4, 4, 1, 2, 4, 3, 4, 4, 4, 1, 2, 1, 1, 2, 3, 4,\n",
       "       0, 2, 3, 1, 3, 2, 3, 4, 4, 3, 4, 3, 3, 3, 4, 1, 4, 0, 4, 3, 4, 4,\n",
       "       1, 2, 3, 4, 3, 1, 4, 4, 3, 4, 4, 4, 4, 4, 4, 1, 3, 4, 4, 4, 1, 4,\n",
       "       3, 1, 4, 4, 4, 1, 0, 1, 4, 1, 3, 4, 3, 2, 2, 4, 1, 2, 2, 1, 2, 4,\n",
       "       1, 4, 2, 3, 4, 2, 4, 4, 3, 0, 4, 4, 3, 4, 2, 4, 4, 3, 4, 4, 4, 4,\n",
       "       1, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 3, 2, 4, 3, 4, 1, 4, 3, 4,\n",
       "       3, 4, 4, 3, 4, 1, 0, 1, 3, 4, 3, 4, 4, 2, 3, 4, 4, 3, 3, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 2, 3, 2, 2, 3, 3, 4, 3, 4, 4, 3, 1,\n",
       "       4, 4, 2, 4, 3, 4, 4, 4, 0, 4, 3, 3, 3, 2, 1, 4, 3, 3, 2, 4, 2, 2,\n",
       "       3, 4, 4, 2, 4, 3, 3, 4, 0, 2, 4, 4, 3, 4, 4, 4, 4, 1, 4, 4, 4, 3,\n",
       "       1, 4, 3, 4, 2, 4, 4, 0, 3, 4, 4, 2, 4, 2, 1, 3, 4, 1, 4, 2, 3, 4,\n",
       "       4, 3, 1, 4, 1, 2, 1, 3, 3, 4, 0, 4, 4, 4, 1, 4, 4, 4, 1, 1, 4, 1,\n",
       "       1, 4, 4, 4, 3, 2, 2, 3, 0, 4, 4, 4, 2, 4, 4, 4, 3, 3, 3, 0, 2, 4,\n",
       "       4, 3, 4, 2, 3, 1, 4, 1, 4, 3, 4, 1, 4, 4, 3, 2, 3, 2, 4, 4, 4, 1,\n",
       "       4, 4, 4, 2, 3, 4, 2, 3, 2, 3, 3, 4, 1, 3, 1, 4, 2, 4, 0, 4, 3, 4,\n",
       "       1, 3, 4, 4, 2, 4, 1, 3, 3, 1, 2, 2, 4, 4, 4, 0, 4, 4, 3, 2, 1, 3,\n",
       "       4, 2, 2, 4, 4, 3, 3, 1, 4, 2, 1, 1, 4, 2], dtype=int64)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing \n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "# Encode labels in column 'sentiment'. \n",
    "Y= label_encoder.fit_transform(Y) \n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "42ae5317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape : Counter({4: 189, 3: 91, 2: 58, 1: 54, 0: 18})\n",
      "Resampled dataset shape Counter({4: 189, 3: 189, 1: 189, 0: 189, 2: 189})\n"
     ]
    }
   ],
   "source": [
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "print(f'Original dataset shape : {Counter(Y)}')\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X, Y)\n",
    "\n",
    "print(f'Resampled dataset shape {Counter(y_res)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0f38241f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Divide the dataset into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b2b0f367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Test Accuracy: 0.4853658536585367\n",
      "Naive Bayes Test Accuracy: 0.573170731707317\n"
     ]
    }
   ],
   "source": [
    "#creating the objects\n",
    "\n",
    "svc_cv=SVC()\n",
    "nb_cv=BernoulliNB()\n",
    "cv_dict = {0: 'SVM', 1: 'Naive Bayes'}\n",
    "cv_models=[svc_cv,nb_cv]\n",
    "\n",
    "\n",
    "for i,model in enumerate(cv_models):\n",
    "    print(\"{} Test Accuracy: {}\".format(cv_dict[i],cross_val_score(model, X,Y, cv=10, scoring ='accuracy').mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7d1ec4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf025782",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01e53bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdf37d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c509888b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff043086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0550b120",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36229e59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8440ce54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4e4c82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a03088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d707d313",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a47f91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26191ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808eb3f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52a9d38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8ec669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bcc06d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3562085",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3700b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76247eaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c10d62d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45169ff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c03dea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b364713a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5963f8df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6603a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70df0c21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e7dc53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607eba08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc3117f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354fd90a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6947b50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4c02ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d63343c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786e5337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c795049",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778d4dce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43df4241",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984d7556",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57817c79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93d6f28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f619656c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efce0caa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7522cc87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e28e290",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6779a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1450afa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79527881",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7803923",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baf9a49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d6eee4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc287723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ae5dac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cf1ad8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c53564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3825696",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8c0878",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c5ed72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6af1eb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0d1abd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6587889a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c90943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3de696b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd7f29d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ed2d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3373cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6974b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cf4f81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffcafc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d6096a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be8eaeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833d8354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28fdaea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb9ce1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199aee9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2a2579",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38e7ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753a56c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b0b6ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
